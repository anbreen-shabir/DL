# Import necessary libraries
import numpy as np
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical

# Load the MNIST dataset
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# Preprocess the data
train_images = train_images.reshape((60000, 28 * 28)) / 255.0   # Normalize and flatten training images
test_images = test_images.reshape((10000, 28 * 28)) / 255.0     # Normalize and flatten test images

# Convert labels to categorical (one-hot encoding)
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

# Build the neural network model
model = Sequential([
    Dense(64, activation='relu', input_shape=(28 * 28,)),  # First hidden layer with ReLU activation
    Dense(10, activation='softmax')                        # Output layer with softmax activation
])

# Compile the model
model.compile(
    optimizer='adam',                    # Optimizer: Adam (adaptive gradient descent)
    loss='categorical_crossentropy',      # Loss function: Categorical Crossentropy for multi-class classification
    metrics=['accuracy']                 # Metric: Accuracy to evaluate model performance
)

# Train the model using the training data
history = model.fit(
    train_images, train_labels,          # Training data and labels
    epochs=10,                           # Number of epochs (iterations over the dataset)
    batch_size=128,                      # Number of samples per gradient update
    validation_split=0.1                 # Use 10% of the training data for validation
)

# Evaluate the model on the test data
test_loss, test_acc = model.evaluate(test_images, test_labels)
print(f'Test accuracy: {test_acc:.4f}')
